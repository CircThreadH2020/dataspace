# https://www.haproxy.org/
# https://www.haproxy.com/blog/how-to-run-haproxy-with-docker/
# https://www.haproxy.com/blog/haproxy-configuration-basics-load-balance-your-servers/
# https://www.haproxy.com/blog/introduction-to-haproxy-acls/
# https://www.haproxy.com/blog/using-haproxy-as-an-api-gateway-part-1/
# https://www.haproxy.com/blog/four-examples-of-haproxy-rate-limiting/
# https://www.haproxy.com/blog/the-four-essential-sections-of-an-haproxy-configuration/
# https://www.haproxy.com/blog/introduction-to-haproxy-stick-tables
# https://www.haproxy.com/documentation/haproxy-configuration-tutorials/core-concepts/stick-tables/

# fall: how many failed health checks are required to flag a server is not available.
# rise: how many successful health checks are required to flag a server is available .
# maxconn: Up to N connections can be established at once to the server. Any more than that will be queued.
# timeout: You can define how long clients should be queued by adding the timeout queue setting.
#   Maximum time to wait in the queue for a connection slot to be free.
#   When a server's maxconn is reached, connections are left pending in a queue which may be server-specific or
#   global to the backend. In order not to wait indefinitely, a timeout is applied to requests pending in the queue.
#   If the timeout is reached, it is considered that the request will almost never be served, so it is dropped and
#   a 503 error is returned to the client.

# https://www.haproxy.com/blog/haproxy-ssl-termination/
# https://serversforhackers.com/c/using-ssl-certificates-with-haproxy

global
  #stats socket /var/run/api.sock user haproxy group haproxy mode 660 level admin expose-fd listeners
  log stdout format raw local0 info
  ssl-default-bind-options ssl-min-ver TLSv1.2    # only TLS version 1.2 and newer is allowed

defaults
  mode http
  log global
  option httplog
  option log-health-checks
  option forwardfor         # requires http mode, Enable insertion of the X-Forwarded-For header to requests sent to servers
  timeout client  10s       # maximum inactivity time on the client side
                            # it applies when the client is expected to acknowledge or send data
                            # In TCP mode, (and to a lesser extent, in HTTP mode), it is highly recommended that the
                            #   client timeout remains equal to the server timeout in order to avoid complex situations to debug
  timeout connect 5s        # maximum time to wait for a connection attempt to a server to succeed
  timeout server  20s       # maximum time for pending data staying into output buffer
                            # it applies when the server is expected to acknowledge or send data
  timeout http-request 20s  # maximum allowed time to wait for a complete HTTP request

# -------------------------------------------------------------------------------------
# About the stick-table:
#   It's a table for tracking the metrics of each IP address (of of another item) that accesses the proxy.
#   A stick table tracks data types (also known as counters) that count the occurrences of specific events.
#   Can store up to X million records and each expire after Y duration, unless it is accessed during that time.
#   Tracking is done by 'http-request track-sc0', 'tcp-request connection track-sc0' or 'tcp-request content track-sc0' (using the stick counter 'sc0').
#   '... track-sc0' adds/updates a record to the table
#   'sc' == stick counter: variable that temporarily holds the input sample to look up as the primary key in the stick table (e.g. the IP address).
#   'http-request track-sc0': inserts or updates a record in a stick table, the sc0 part specifies the sticky counter to use.
#   By default, there are three variants: track-sc0 track-sc1 track-sc2
#   All fetch methods that retrieve a record from a stick table use the ID of the sticky counter that holds the key (e.g. IP adress), e.g. 'sc_http_req_rate(0,mysticktable)'
#   General-purpose counters: can be incremented manually, e.g. 'gpc0' and 'gpc1'.
#
#   https://www.haproxy.com/blog/introduction-to-haproxy-stick-tables:
#   'http_req_rate(<period>)': average HTTP request rate over the period, in requests per period, regardless of whether the requests are accepted or not.
#   'http_err_rate(<period>)': average HTTP request error rate over the period, in requests per period 
#     (Errors are counted on invalid and truncated requests, as well as on denied or tarpitted requests, and on failed authentications. 
#      If the server responds with 4xx, then the request is also counted as an error).
#   'conn_cur': is automatically incremented or decremented when the 'tcp-request content track-sc0 src' line is processed to reflect the number of currently open connections for the key, or source IP.
#   'conn_rate': is similar but is given a period of time and calculates an average rate of new connections over that period (average incoming connection rate over the period, in connections per period). 
# -------------------------------------------------------------------------------------

# The aim of this section is to define a stick table for tracking the TCP metrics (layer 4) of each IP address that accesses the proxy
backend tcp-stick-table
  stick-table type ip size 1m expire 15m store conn_rate(5s),conn_cur

# The aim of this section is to define a stick table for tracking the HTTP metrics (layer 7) of each IP address that accesses the proxy
# Policy implemented in the front end:
#   -If the rate of http reqs or http errors coming from an IP address is high (in a 15s time window), that IP is blocked (for 15 minutes).
#   -Tracking is then diabled and stays disabled until the record expires (after 15 minutes). It is enabled authomatically when the record is created. 
backend http-stick-table
  stick-table type ip size 1m expire 15m store gpc0,http_req_rate(15s),http_err_rate(15s)

# -------------------------------------------------------------------------------------
# FRONT END section
# -------------------------------------------------------------------------------------

frontend public
  bind 0.0.0.0:8080 ssl crt /usr/local/etc/haproxy/server.pem 
  bind 0.0.0.0:8090 ssl crt /usr/local/etc/haproxy/server.pem

  # Track & Reject TCP connections (sc1 is the sticky counter sc1)
  tcp-request connection track-sc1 src table tcp-stick-table
  tcp-request connection reject if { sc1_conn_cur(tcp-stick-table)  gt 20 }    # no more than 20 concurrent connections
  tcp-request connection reject if { sc1_conn_rate(tcp-stick-table) gt 20 }    # no more than 20 concurrent connections in 5 seconds

  # Track & Deny HTTP connections if gpc0 == 0 (sc0 is the sticky counter)
  http-request track-sc0 src table http-stick-table if { src_get_gpc0(http-stick-table) eq 0 }  
  # Detect HTTP possible attack
  acl too-many-http-reqs src_http_req_rate(http-stick-table) gt 120        # 8 reqs per second
  acl too-many-http-errs src_http_err_rate(http-stick-table) gt 90         # 6 req errs per second
  # Increment gpc0 (flag that triggers the blocking of the IP)
  http-request sc-inc-gpc0(0) if too-many-http-reqs { src_get_gpc0(http-stick-table) eq 0 }
  http-request sc-inc-gpc0(0) if too-many-http-errs { src_get_gpc0(http-stick-table) eq 0 }
  # Deny HTTP request if the IP is blocked (gpc0 > 0)
  http-request deny if { src_get_gpc0(http-stick-table) gt 0 }

  http-request set-header X-Forwarded-Proto %[ssl_fc,iif(https,http)]

  # Redirect http traffic to https
  http-request redirect scheme https code 301 unless { ssl_fc }

  use_backend circthread-connector  if { path_beg /<REPLACE_WITH_CONNECTOR_MANAGER_UNIQUE_ID> }  { dst_port 8080 }
  use_backend circthread-app4edi    if { path_beg /<REPLACE_WITH_CONNECTOR_MANAGER_UNIQUE_ID> }  { dst_port 8090 }

# -------------------------------------------------------------------------------------
# BACK END section
# -------------------------------------------------------------------------------------

# https://www.haproxy.com/blog/how-to-enable-health-checks-in-haproxy/
# We use active health check on each backend (uri=="/" for the connector and uri=="keep-alive" on the app4edi:
#   inter 30s - haproxy establishes a TCP connection every 30 secs
#   fall   4  - how many failed checks are allowed, after 4 failed connections, the server is removed, temporarily
#   rise   1  - how many passing checks there must be before returning a previously failed server to the pool

# maxconn 20        - limits to 20 the maximum number of connections that HAProxy will accept
# timeout queue 10s - a client will wait for up to 10 seconds in the queue, after which HAProxy returns a 503 Service Unavailable response to them

backend circthread-connector
  timeout queue 10s
  option httpchk
  http-check connect default
  http-check send meth GET uri /<REPLACE_WITH_CONNECTOR_MANAGER_UNIQUE_ID>/
  http-check expect status 200
  server circthread-connector  circthread-connector:8080  check inter 30s fall 4 rise 1  maxconn 20 ssl verify none

backend circthread-app4edi
  timeout queue 10s
  option httpchk
  http-check connect default
  http-check send meth GET uri /<REPLACE_WITH_CONNECTOR_MANAGER_UNIQUE_ID>/keep-alive
  http-check expect status 200
  server circthread-app4edi    circthread-app4edi:8090    check inter 30s fall 4 rise 1  maxconn 20 ssl verify none
